server:
  port: 12804
  http2:
    enabled: true
spring:
  main:
    allow-bean-definition-overriding: true
  application:
    name: linmour-order
  profiles:
    active: dev


# grpc配置
grpc:
  server:
    port: 29898
  # grpc clienT相关配置
  client:
    # 服务名（不同服务名可对应不同配置）
    # nacos-grpc是服务端配置的名字，GrpcClient注解会用到
    nacos-grpc:
      address: 'static://127.0.0.1:19898'
      # 是否开启保持连接（长连接）
      enableKeepAlive: true
      # 保持连接时长（默认20s）
      keepAliveTimeout: 20s
      # 没有RPC调用时是否保持连接（默认false，可禁用避免额外消耗CPU）
      keepAliveWithoutCalls: false
      # 客户端负载均衡策略(round_robin（默认）, pick_first)
      defaultLoadBalancingPolicy: round_robin
      # 通信类型
      # plaintext | plaintext_upgrade | tls
      # 明文通信且http/2 | 明文通信且升级http/1.1为http/2 | 使用TLS（ALPN/NPN）通信
      negotiationType: plaintext
    another-service:
      address: 'static://127.0.0.1:20001'
      enableKeepAlive: true
      # 保持连接时长（默认20s）
      keepAliveTimeout: 20s
      # 没有RPC调用时是否保持连接（默认false，可禁用避免额外消耗CPU）
      keepAliveWithoutCalls: false
      # 客户端负载均衡策略(round_robin（默认）, pick_first)
      defaultLoadBalancingPolicy: round_robin
      # 通信类型
      # plaintext | plaintext_upgrade | tls
      # 明文通信且http/2 | 明文通信且升级http/1.1为http/2 | 使用TLS（ALPN/NPN）通信
      negotiationType: plaintext
---
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://120.79.7.243:3306/lsc_order?characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&rewriteBatchedStatements=true
    username: root
    password: cheng128
# 设置Mapper接口所对应的XML文件位置，如果你在Mapper接口中有自定义方法，需要进行该配置
mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  mapper-locations: classpath*:mapper/*.xml
  # 设置别名包扫描路径，通过该属性可以给包中的类注册别名
  type-aliases-package: com.linmour.order.pojo
  global-config:
    db-config:
      #      设置逻辑删除，在执行sql时会自动拼接
      logic-delete-field: deleted
      logic-delete-value: 1
      logic-not-delete-value: 0
---
spring:
  redis:
    # password: 123456
    # host: 192.168.1.135
    password: cheng128
    host: 120.79.7.243
    database: 2
#redisson:
#  codec: org.redisson.codec.JsonJacksonCodec
#  threads: 4
#  netty:
#    threads: 4
#  single-server-config:
#    # address: "redis://192.168.1.135:6379"
#    # password: 123456
#    address: "redis://120.79.7.243:6379"
#    password: cheng128
#    database: 2

xxl:
  job:
    admin:
      addresses: http://localhost:9090/xxl-job-admin
    # accessToken: 1
    executor:
      appname: linmour
      # address:
      ip:
      port: 9999
      # 日志地址
      logpath: /data/applogs/xxl-job/jobhandler
      # 日志保存时间
      logretentiondays: 30




seata:
  tx-service-group: mygroup # 事务分组名称，要和服务端对应
  service:
    vgroup-mapping:
      mygroup: default # key是事务分组名称 value要和服务端的机房名称保持一致

---
spring:
  kafka:
    bootstrap-servers: 120.79.7.243:9092 #这个是kafka的地址,对应你server.properties中配置的
    producer:
      batch-size: 16384 #批量大小
      acks: -1 #应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      retries: 10 # 消息发送重试次数
      #transaction-id-prefix: transaction
      buffer-memory: 33554432
      key-serializer: com.linmour.mq.serializer.KafkaSerializer
      value-serializer: com.linmour.mq.serializer.KafkaSerializer
      # key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        spring.json.key.type: java.lang.String
        spring.json.key.serializer: com.linmour.mq.serializer.StringSerializer
        spring.json.value.type: java.lang.String
        spring.json.value.serializer: com.linmour.mq.serializer.StringSerializer
        linger:
          ms: 2000 #提交延迟
          #partitioner: #指定分区器
          #class: pers.zhang.config.CustomerPartitionHandler
    consumer:
      group-id: testGroup #默认的消费组ID
      enable-auto-commit: true #是否自动提交offset
      auto-commit-interval: 2000 #提交offset延时
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      max-poll-records: 500 #单次拉取消息的最大条数
      key-deserializer: com.linmour.mq.serializer.KafkaDeserializer
      value-deserializer: com.linmour.mq.serializer.KafkaDeserializer
      # key-serializer: org.apache.kafka.common.serialization.Deserializer;
      # value-serializer: org.apache.kafka.common.serialization.Deserializer;
      properties:
        session:
          timeout:
            ms: 120000 # 消费会话超时时间（超过这个时间 consumer 没有发送心跳，就会触发 rebalance 操作）
        request:
          timeout:
            ms: 18000 # 消费请求的超时时间
    streams:
      application-id: kafka-streams-example-app # 您的 Kafka Streams 应用程序的应用程序 ID
      properties:
        # 覆盖默认的 StreamsConfig 属性
        # 有关更多配置选项，请参阅 Kafka Streams 文档
        cache.max.bytes.buffering: 0
    listener:
      missing-topics-fatal: false # consumer listener topics 不存在时，启动项目就会报错
      type: batch # 设置 listener 类型为 batch，以启用批量处理
wx:
  appid: wx2728606f5f2b4621
  secret: 9ecbe72e173907443e9742803a980533